name: Claude Code Review

on:
  pull_request:
    types: [opened, ready_for_review]  # When PR is ready for review (not draft)
  issue_comment:
    types: [created]  # Listen for @claude mentions in PR comments

jobs:
  claude-review:
    # Run if: (PR opened/ready AND not draft) OR @claude review in PR comment
    if: |
      (github.event_name == 'pull_request' && !github.event.pull_request.draft) ||
      (github.event_name == 'issue_comment' &&
       github.event.issue.pull_request &&
       (contains(github.event.comment.body, '@claude review') ||
        contains(github.event.comment.body, '@claude code review')))

    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
      issues: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Fetch PR Comments Context
        id: fetch-comments
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ github.event.pull_request.number || github.event.issue.number }}
          REPO_OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
        run: |
          # GraphQL query to fetch all PR comments and review threads
          QUERY='query($owner: String!, $repo: String!, $prNumber: Int!) {
            repository(owner: $owner, name: $repo) {
              pullRequest(number: $prNumber) {
                comments(first: 100) {
                  totalCount
                  nodes {
                    author { login }
                    body
                    createdAt
                  }
                }
                reviewThreads(first: 100) {
                  totalCount
                  nodes {
                    isResolved
                    isOutdated
                    path
                    line
                    comments(first: 50) {
                      nodes {
                        author { login }
                        body
                        createdAt
                        diffHunk
                      }
                    }
                  }
                }
                reviews(first: 50) {
                  totalCount
                  nodes {
                    author { login }
                    body
                    state
                    createdAt
                  }
                }
              }
            }
          }'

          # Execute GraphQL query and check for errors
          if ! COMMENTS_JSON=$(gh api graphql \
            -f query="$QUERY" \
            -f owner="$REPO_OWNER" \
            -f repo="$REPO_NAME" \
            -F prNumber="$PR_NUMBER"); then
            echo "Warning: Failed to fetch PR comments. Proceeding without comment context."
            echo "⚠️ Unable to fetch existing comments due to API error." > /tmp/pr_comments_context.txt
            exit 0
          fi

          # Format comments for Claude using Python
          export COMMENTS_JSON
          python3 <<'PYTHON' > /tmp/pr_comments_context.txt
          import json
          import os
          import sys

          def get_author(node):
              """Safely get author login, handling deleted accounts."""
              author = node.get('author')
              return author.get('login', 'ghost') if author else 'ghost'

          try:
              data = json.loads(os.environ['COMMENTS_JSON'])

              # Check for GraphQL errors
              if 'errors' in data:
                  error_msg = data['errors'][0].get('message', 'Unknown error')
                  print(f"⚠️ GitHub API error: {error_msg}")
                  sys.exit(0)

              pr = data.get('data', {}).get('repository', {}).get('pullRequest')
              if not pr:
                  print("⚠️ No PR data found in API response.")
                  sys.exit(0)

          except (json.JSONDecodeError, KeyError) as e:
              print(f"⚠️ Unable to parse comment data: {e}")
              sys.exit(0)

          output = []
          output.append("=" * 80)
          output.append("EXISTING PR COMMENTS AND DISCUSSIONS")
          output.append("=" * 80)
          output.append("")

          # Section 1: General PR Comments
          comments_data = pr.get('comments', {})
          issue_comments = comments_data.get('nodes', [])
          total_comments = comments_data.get('totalCount', 0)

          if issue_comments:
              output.append("## General PR Comments")
              output.append("")
              for comment in issue_comments:
                  author = get_author(comment)
                  created = comment.get('createdAt', '')[:10]
                  body = comment.get('body', '').strip()
                  output.append(f"### Comment by @{author} on {created}")
                  output.append(body)
                  output.append("")
                  output.append("-" * 40)
                  output.append("")

              if total_comments > 100:
                  output.append(f"*Note: This PR has {total_comments} comments. Showing first 100.*")
                  output.append("")
          else:
              output.append("## General PR Comments")
              output.append("No general comments found.")
              output.append("")

          # Section 2: Review Summaries
          reviews_data = pr.get('reviews', {})
          reviews = reviews_data.get('nodes', [])

          if reviews:
              output.append("## Review Summaries")
              output.append("")
              for review in reviews:
                  if review.get('body'):
                      author = get_author(review)
                      state = review.get('state', 'COMMENTED')
                      created = review.get('createdAt', '')[:10]
                      body = review.get('body', '').strip()
                      output.append(f"### {state} Review by @{author} on {created}")
                      output.append(body)
                      output.append("")
                      output.append("-" * 40)
                      output.append("")

          # Section 3: Inline Code Review Comments (grouped by thread)
          threads_data = pr.get('reviewThreads', {})
          review_threads = threads_data.get('nodes', [])
          total_threads = threads_data.get('totalCount', 0)

          unresolved = [t for t in review_threads if not t.get('isResolved', False)]
          resolved = [t for t in review_threads if t.get('isResolved', False)]

          if unresolved:
              output.append("## Unresolved Code Review Discussions")
              output.append("")
              for thread in unresolved:
                  path = thread.get('path', 'unknown')
                  line = thread.get('line')
                  line_str = f"L{line}" if line else "file-level"
                  is_outdated = thread.get('isOutdated', False)
                  outdated_marker = " [OUTDATED]" if is_outdated else ""

                  output.append(f"### Thread: {path}:{line_str}{outdated_marker}")
                  output.append(f"**Status:** UNRESOLVED")
                  output.append("")

                  comments = thread.get('comments', {}).get('nodes', [])
                  for i, comment in enumerate(comments):
                      author = get_author(comment)
                      body = comment.get('body', '').strip()
                      created = comment.get('createdAt', '')[:10]

                      # Show diff hunk for first comment (truncate if too long)
                      if i == 0 and comment.get('diffHunk'):
                          diff_hunk = comment['diffHunk']
                          if len(diff_hunk) > 500:
                              diff_hunk = diff_hunk[:500] + "\n... (truncated)"
                          output.append("**Code context:**")
                          output.append("```")
                          output.append(diff_hunk)
                          output.append("```")
                          output.append("")

                      prefix = "Original comment" if i == 0 else f"Reply {i}"
                      output.append(f"**{prefix} by @{author} on {created}:**")
                      output.append(body)
                      output.append("")

                  output.append("-" * 40)
                  output.append("")
          else:
              output.append("## Unresolved Code Review Discussions")
              output.append("No unresolved discussions.")
              output.append("")

          if resolved:
              output.append("## Resolved Code Review Discussions")
              output.append("")
              for thread in resolved:
                  path = thread.get('path', 'unknown')
                  line = thread.get('line')
                  line_str = f"L{line}" if line else "file-level"

                  output.append(f"### Thread: {path}:{line_str}")
                  output.append(f"**Status:** RESOLVED")
                  output.append("")

                  comments = thread.get('comments', {}).get('nodes', [])
                  for i, comment in enumerate(comments):
                      author = get_author(comment)
                      body = comment.get('body', '').strip()
                      created = comment.get('createdAt', '')[:10]

                      prefix = "Original comment" if i == 0 else f"Reply {i}"
                      output.append(f"**{prefix} by @{author} on {created}:**")
                      output.append(body)
                      output.append("")

                  output.append("-" * 40)
                  output.append("")
          else:
              output.append("## Resolved Code Review Discussions")
              output.append("No resolved discussions.")
              output.append("")

          if total_threads > 100:
              output.append(f"*Note: This PR has {total_threads} review threads. Showing first 100.*")
              output.append("")

          output.append("=" * 80)
          output.append("END OF EXISTING COMMENTS")
          output.append("=" * 80)

          print("\n".join(output))
          PYTHON

      - name: Run Claude Code Review
        id: claude-review
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          prompt: |
            <pr_context>
            REPO: ${{ github.repository }}
            PR NUMBER: ${{ github.event.pull_request.number || github.event.issue.number }}
            LANGUAGE: Rust
            </pr_context>

            <existing_discussions>
            $(cat /tmp/pr_comments_context.txt)
            </existing_discussions>

            <review_instructions>
            Analyze this pull request focusing on CRITICAL issues only. Keep feedback concise and actionable.

            **IMPORTANT - CONTEXT AWARENESS:**
            - Review the <existing_discussions> section above before providing feedback
            - Acknowledge and reference previous discussions when relevant
            - If a resolved thread addressed an issue, note that it was already fixed
            - Build upon previous feedback rather than duplicating it

            PRIORITY CHECKS (report only if found):
            1. Logic & Functionality
               - Logic flaws or incorrect implementations
               - Missing edge cases (empty inputs, boundary conditions, None/Some variants)
               - Unhandled error paths or panics in production code
               - Backward compatibility issues with existing APIs/data formats

            2. Production Safety (multi-cluster deployment context)
               - Breaking changes that could fail during rolling updates
               - State migration issues between old/new versions
               - Race conditions or data consistency problems
               - Resource leaks (memory, file handles, connections)

            3. Database & Data Handling
               - SQL injection risks or unsafe query construction
               - N+1 query problems (queries in loops)
               - Missing indexes causing slow queries (check query patterns)
               - Missing or improper transaction boundaries
               - Database migrations: ensure backward compatibility, no data loss

            4. Performance & Efficiency
               - Blocking operations in async functions (sync I/O, CPU-intensive work)
               - Excessive memory allocations or large data structures
               - Sequential operations that should be parallel (use tokio::join!/select!)
               - Missing timeouts on external calls (HTTP, database, vLLM)
               - Connection pool exhaustion risks

            5. Rust-Specific Concerns
               - Unnecessary .clone() calls (suggest borrows/references instead)
               - Unsafe code without safety comments explaining invariants
               - Incorrect ownership patterns or lifetime issues
               - Improper error handling (unwrap/expect in library code)
               - Concurrency issues (Arc/Mutex misuse, data races)

            6. Code Quality
               - Poor modularity (functions >100 lines, god objects)
               - Unclear naming or missing documentation for public APIs
               - Violated Single Responsibility Principle
               - Security vulnerabilities (injection, hardcoded secrets)

            REVIEW STYLE:
            - List only CRITICAL issues that need fixing before merge
            - Use bullet points, be direct and specific
            - Provide code examples for suggested fixes when helpful
            - If no critical issues: approve with brief summary
            - Sign off with: ✅ (approved) or ⚠️ (issues found)

            Consult the repository's CLAUDE.md file (if present) for project-specific conventions.
            Use `gh pr comment` to post your review.
            </review_instructions>
          claude_args: '--allowed-tools "Bash(gh issue view:*),Bash(gh search:*),Bash(gh issue list:*),Bash(gh pr comment:*),Bash(gh pr diff:*),Bash(gh pr view:*),Bash(gh pr list:*)"'

