# Cloud API Configuration via Environment Variables
# Copy this file to .env and fill in your actual values

# =============================================================================
# Server Configuration
# =============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=3000

# =============================================================================
# Model Discovery Configuration
# =============================================================================
# URL of the model discovery server
MODEL_DISCOVERY_SERVER_URL=http://localhost:8080/models

# API key for authenticating with discovered model providers
MODEL_DISCOVERY_API_KEY=YOUR_API_KEY_HERE

# How often to refresh model list (in seconds)
MODEL_DISCOVERY_REFRESH_INTERVAL=300

# Discovery request timeout (in seconds)
MODEL_DISCOVERY_TIMEOUT=5

# Model inference timeout (in seconds) - set to 30 minutes for large models
MODEL_INFERENCE_TIMEOUT=18000

# =============================================================================
# Logging Configuration
# =============================================================================
# Global log level: trace, debug, info, warn, error
LOG_LEVEL=info

# Log format: json, compact, pretty
# Use 'json' for containerized environments with Datadog agent
# Use 'compact' for local development
# Use 'pretty' for debugging
LOG_FORMAT=json

# Module-specific log levels (optional)
LOG_MODULE_API=info
LOG_MODULE_SERVICES=info

# =============================================================================
# DStack Client Configuration
# =============================================================================
DSTACK_CLIENT_URL=http://localhost:8000

# =============================================================================
# Authentication Configuration
# =============================================================================
# Set to true to use mock authentication (development only)
AUTH_MOCK=false

# Set for JWT access token encoding
AUTH_ENCODING_KEY=YOUR_AUTH_ENCODING_KEY

# GitHub OAuth Configuration
# To set up:
# 1. Go to https://github.com/settings/developers
# 2. Create a new OAuth App
# 3. Set Authorization callback URL to: http://your-domain:3000/v1/auth/callback
# 4. Copy Client ID and Client Secret here
GITHUB_CLIENT_ID=YOUR_GITHUB_CLIENT_ID
GITHUB_CLIENT_SECRET=YOUR_GITHUB_CLIENT_SECRET
GITHUB_REDIRECT_URL=http://localhost:3000/v1/auth/callback

# Google OAuth Configuration
# To set up:
# 1. Go to https://console.cloud.google.com/apis/credentials
# 2. Create OAuth 2.0 Client ID
# 3. Add authorized redirect URI: http://your-domain:3000/v1/auth/callback
# 4. Copy Client ID and Client Secret here
GOOGLE_CLIENT_ID=YOUR_GOOGLE_CLIENT_ID.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=YOUR_GOOGLE_CLIENT_SECRET
GOOGLE_REDIRECT_URL=http://localhost:3000/v1/auth/callback

# Admin Configuration
# Comma-separated list of email domains that are granted admin access
# Example: near.ai,admin.org
AUTH_ADMIN_DOMAINS=near.ai

# =============================================================================
# Database Configuration
# =============================================================================
# Primary app ID for Patroni/PostgreSQL cluster discovery
POSTGRES_PRIMARY_APP_ID=your-app-id

DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=platform_api
DATABASE_USERNAME=postgres
DATABASE_PASSWORD=postgres
DATABASE_MAX_CONNECTIONS=5

# TLS/SSL for remote database connections (e.g., DigitalOcean, AWS RDS)
DATABASE_TLS_ENABLED=false

# Path to custom CA certificate (optional, for databases with custom certs)
# DATABASE_TLS_CA_CERT_PATH=path/to/ca-certificate.crt

# Database migration SQL files directory (optional, for custom migration files path)
# DATABASE_MIGRATIONS_PATH=path/to/migrations/sql/directory

# =============================================================================
# AWS S3 Configuration (for file uploads)
# =============================================================================
# S3 bucket name for file storage
AWS_S3_BUCKET=your-bucket-name

# AWS S3 region
AWS_S3_REGION=us-east-1

# AWS credentials (alternatively, use AWS CLI/environment credentials)
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key

# S3 Encryption Key Configuration
# Encryption key for files stored in S3 (must be 256-bit / 32 bytes, hex-encoded)
# Generate a key: openssl rand -hex 32
# Use either S3_ENCRYPTION_KEY or S3_ENCRYPTION_KEY_FILE (mounted secret in production)
S3_ENCRYPTION_KEY=your-hex-encoded-256-bit-encryption-key
# S3_ENCRYPTION_KEY_FILE=/path/to/encryption-key-file

# =============================================================================
# Optional: Configuration Loading Mode
# =============================================================================
# Uncomment to explicitly use environment variables instead of config.yaml
# USE_ENV_CONFIG=true

# Or specify a custom config file path
# CONFIG_FILE=config/custom.yaml

# =============================================================================
# Integration Test Configuration (Optional)
# =============================================================================
# These variables are used by integration tests. If not set, tests will use
# default values suitable for local testing.

# vLLM Integration Tests
# VLLM_BASE_URL=http://localhost:8002
# VLLM_API_KEY=your_vllm_api_key_here
# VLLM_TEST_TIMEOUT_SECS=30


BRAVE_SEARCH_PRO_API_KEY=MY_KEY
